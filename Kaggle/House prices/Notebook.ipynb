{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_coef(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Calculates coefficient of determination \n",
    "    \"\"\"\n",
    "    u,v = 0,0\n",
    "    for i in range(len(y_true)):\n",
    "        u += (y_true[i] - y_pred[i])**2\n",
    "        v += (y_true[i] - np.mean(y_true))**2\n",
    "    print(\"Coefficient of determination is: \",float(1 - u/v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data\n",
    "TRAIN_FILEPATH = \"Data/train.csv\"\n",
    "TEST_FILEPATH  = \"Data/test.csv\"\n",
    "\n",
    "Training_data = pd.read_csv(TRAIN_FILEPATH)\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "[i for i in range(2*len(a)) if i not in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Viewing data\n",
    "Training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 266500, 142125, 147500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extracting sales prices (labels) as numpy array\n",
    "Labels = Training_data[\"SalePrice\"].values\n",
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extraxting feature names \n",
    "Feature_names = Training_data.columns[1:-1]\n",
    "Feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of NaN features: 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting features not represented by a number \n",
    "NaN_features = []\n",
    "for index, datatype in enumerate(Training_data.dtypes):\n",
    "    if datatype == \"O\" or datatype == object:\n",
    "        NaN_features.append(Training_data.columns[index])\n",
    "print(\"Nr. of NaN features:\",len(NaN_features))\n",
    "NaN_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary of dictionaries\n",
    "\"\"\"A dictionary for each NaN feature, mapping k'th possible val for that feature to int(k)\"\"\"\n",
    "NaN_feature_dicts = {}\n",
    "for feature_idx,feature in enumerate(NaN_features):\n",
    "    ith_feature_dict = {}\n",
    "    for val_idx, possible_val in enumerate(np.unique(list(Training_data[NaN_features[feature_idx]]))):\n",
    "        ith_feature_dict[str(possible_val)] = val_idx\n",
    "    NaN_feature_dicts[feature] = ith_feature_dict   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### First NaN feature: MSZoning ####################\n",
      "\n",
      "Dict of possible vals for first NaN feature:\n",
      " {'C (all)': 0, 'FV': 1, 'RH': 2, 'RL': 3, 'RM': 4}\n",
      "\n",
      "List of keys: \n",
      " ['C (all)', 'FV', 'RH', 'RL', 'RM']\n",
      "\n",
      "list of values:\n",
      " [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "## For instance\n",
    "feature = NaN_features[0]\n",
    "print(\"#\"*20+\" First NaN feature:\", feature,\"#\"*20)\n",
    "print(\"\")\n",
    "feature_dict = NaN_feature_dicts[feature]\n",
    "print(\"Dict of possible vals for first NaN feature:\\n\", feature_dict)\n",
    "print(\"\")\n",
    "print(\"List of keys: \\n\",list(feature_dict.keys()))\n",
    "print(\"\")\n",
    "print(\"list of values:\\n\",list(feature_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping all NaN features to numbers in compliance with dictionaries above\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Training_data[feature]))):\n",
    "        value = current_dict[str(Training_data.at[index,feature])] ## Getting\n",
    "        Training_data.at[index,feature] = value                    ## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60        3         65.0     8450      1     2        3   \n",
       "1        2          20        3         80.0     9600      1     2        3   \n",
       "2        3          60        3         68.0    11250      1     2        0   \n",
       "3        4          70        3         60.0     9550      1     2        0   \n",
       "4        5          60        3         84.0    14260      1     2        0   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60        3         62.0     7917      1     2        3   \n",
       "1456  1457          20        3         85.0    13175      1     2        3   \n",
       "1457  1458          70        3         66.0     9042      1     2        3   \n",
       "1458  1459          20        3         68.0     9717      1     2        3   \n",
       "1459  1460          20        3         75.0     9937      1     2        3   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0              3         0  ...        0      3     4           4       0   \n",
       "1              3         0  ...        0      3     4           4       0   \n",
       "2              3         0  ...        0      3     4           4       0   \n",
       "3              3         0  ...        0      3     4           4       0   \n",
       "4              3         0  ...        0      3     4           4       0   \n",
       "...          ...       ...  ...      ...    ...   ...         ...     ...   \n",
       "1455           3         0  ...        0      3     4           4       0   \n",
       "1456           3         0  ...        0      3     2           4       0   \n",
       "1457           3         0  ...        0      3     0           2    2500   \n",
       "1458           3         0  ...        0      3     4           4       0   \n",
       "1459           3         0  ...        0      3     4           4       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008         8              4     208500  \n",
       "1         5   2007         8              4     181500  \n",
       "2         9   2008         8              4     223500  \n",
       "3         2   2006         8              0     140000  \n",
       "4        12   2008         8              4     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007         8              4     175000  \n",
       "1456      2   2010         8              4     210000  \n",
       "1457      5   2010         8              4     266500  \n",
       "1458      4   2010         8              4     142125  \n",
       "1459      6   2008         8              4     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Viewing mapped data\n",
    "Training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  60.,    3.,   65., ..., 2008.,    8.,    4.],\n",
       "       [  20.,    3.,   80., ..., 2007.,    8.,    4.],\n",
       "       [  60.,    3.,   68., ..., 2008.,    8.,    4.],\n",
       "       ...,\n",
       "       [  70.,    3.,   66., ..., 2010.,    8.,    4.],\n",
       "       [  20.,    3.,   68., ..., 2010.,    8.,    4.],\n",
       "       [  20.,    3.,   75., ..., 2008.,    8.,    4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Transforming from Pandas datafram to numpy array \n",
    "Training_data   = Training_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Feature_vectors = Training_data[:,[i+1 for i in range(Training_data.shape[1]-2)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Feature_vectors = Feature_vectors.astype(\"float64\")\n",
    "Feature_vectors = np.nan_to_num(Feature_vectors)\n",
    "Feature_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal linear regression\n",
    "\\begin{equation}\n",
    "\\bold{W} = (\\bold{X}^T\\bold{X})^{-1}\\bold{X}^T\\bold{y}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. deviation before normalization = 18.65 ( 1864.98 %)\n",
      "Avg. deviation after normalization = 0.21 ( 21.01 %)\n",
      "Coefficient of determination is:  0.6186502417886162\n"
     ]
    }
   ],
   "source": [
    "############ LINEAR REGRESSION ############\n",
    "X_init = deepcopy(Feature_vectors)\n",
    "# Adding 1 as first coord to all feature vectors\n",
    "X = np.ones((X_init.shape[0],X_init.shape[1]+1)) \n",
    "for col in range(1,X.shape[1]):\n",
    "    X[:,col] = X_init[:,col-1]\n",
    "# Computing optimal weight vector\n",
    "Y = Labels\n",
    "XT = X.T\n",
    "XTX = XT @ X\n",
    "XTX_INVERSE = np.linalg.inv(XTX)\n",
    "W_optimal = (XTX_INVERSE @ XT) @ Y\n",
    "# Checking predictions\n",
    "def predict(feature_vector,weight):\n",
    "    prediction = 0\n",
    "    # Computing inner product\n",
    "    for i in range(len(feature_vector)):\n",
    "        prediction += feature_vector[i]*weight[i]\n",
    "    return prediction\n",
    "\n",
    "deviation = 0\n",
    "for i in range(len(X)):\n",
    "    deviation += np.abs(predict(X[i],W_optimal)-Labels[i])/np.abs(Labels[i])\n",
    "deviation *= 1./X.shape[0]\n",
    "print(\"Avg. deviation before normalization =\",np.round(deviation,2),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "\n",
    "######## Normalizing s.t. each feature (column) has mean = 0 and then variance = 1 ########\n",
    "# Labels\n",
    "Label_mean, Label_var = np.mean(Labels), np.std(Labels) \n",
    "Labels = Labels - Label_mean     ## mean\n",
    "Labels = Labels * 1./Label_var   ## variance\n",
    "# Feature vectors\n",
    "for col in range(Feature_vectors.shape[1]):\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] - np.mean(Feature_vectors[:,col])       ## mean\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] * 1./np.std(Feature_vectors[:,col])     ## variance\n",
    "\n",
    "\n",
    "X_init_norm = deepcopy(Feature_vectors)\n",
    "# Adding 1 as first coord to all feature vectors\n",
    "X_norm = np.ones((X_init_norm.shape[0],X_init_norm.shape[1]+1)) \n",
    "for col in range(1,X_norm.shape[1]):\n",
    "    X_norm[:,col] = X_init_norm[:,col-1]\n",
    "# Computing optimal weight vector\n",
    "Y_norm = Labels\n",
    "XT_norm = X_norm.T\n",
    "XTX_norm = XT_norm @ X_norm\n",
    "XTX_INVERSE_norm = np.linalg.inv(XTX_norm)\n",
    "W_optimal_norm = (XTX_INVERSE_norm @ XT_norm) @ Y_norm\n",
    "\n",
    "deviation = 0\n",
    "for i in range(len(X_norm)):\n",
    "    deviation += np.abs(predict(X_norm[i],W_optimal_norm)*Label_var+Label_mean-(Y_norm[i]*Label_var+Label_mean))/np.abs(Y_norm[i]*Label_var+Label_mean)\n",
    "deviation *= 1./X.shape[0]\n",
    "print(\"Avg. deviation after normalization =\",np.round(deviation,2),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "y_pred = np.array([predict(X_norm[i],W_optimal_norm)*Label_var+Label_mean for i in range(X_norm.shape[0])]) \n",
    "y_true = Y_norm*Label_var+Label_mean\n",
    "R2_coef(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "#### Predicted price, actual price ####\n",
      "     164322.4       , 129500.0 \n",
      "----------------------------------------\n",
      "####           Deviation           ####\n",
      "                 26.9 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Single predictions (accounting for normalization)\n",
    "nr = 10\n",
    "print(\"-\"*40)\n",
    "print(\"#### Predicted price, actual price ####\")\n",
    "print(\"    \",np.round(predict(X_norm[nr],W_optimal_norm)*Label_var+Label_mean,1),\"      ,\",(Y_norm[nr]*Label_var)+Label_mean,\"\")\n",
    "print(\"-\"*40)\n",
    "print(\"####           Deviation           ####\")\n",
    "dev = np.round(100*np.abs(predict(X_norm[nr],W_optimal_norm)*Label_var+Label_mean-(Y_norm[nr]*Label_var+Label_mean))/np.abs(Y_norm[nr]*Label_var+Label_mean),1)\n",
    "print(f'                 {dev} %')\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Variance-Covariance matrix #########\n",
    "\n",
    "### Removing ones\n",
    "X_norm_new = X_norm[:,[i+1 for i in range(X_norm.shape[1]-1)]]\n",
    "\n",
    "### Calculating square inverse matrix\n",
    "XT_norm_new = X_norm_new.T\n",
    "XTX_norm_new = XT_norm_new @ X_norm_new\n",
    "XTX_INVERSE_norm_new = np.linalg.inv(XTX_norm_new)\n",
    "\n",
    "### Calculating Covariance-variance matrix\n",
    "N, D = X_norm_new.shape[0], X_norm_new.shape[1]-1\n",
    "Y_predictions_norm_new = X_norm_new @ W_optimal_norm[1:]\n",
    "variance = 1./(N-D-1)*np.sum((Y_norm-Y_predictions_norm_new)**2)\n",
    "variance_matrix = XTX_INVERSE_norm_new * variance\n",
    "\n",
    "Plot_n_save = False\n",
    "if Plot_n_save:\n",
    "    ### Plotting and saving \n",
    "    from heatmap_functions import heatmap\n",
    "    from heatmap_functions import annotate_heatmap\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(20,20))\n",
    "    ax.set_title(\"Covariance matrix of normed features\",size=20)\n",
    "    im, cbar = heatmap(data = variance_matrix, row_labels = Feature_names, \n",
    "                       col_labels = Feature_names, ax=ax, cbarlabel=\" \",cmap=\"YlGn\")\n",
    "    texts = annotate_heatmap(im, valfmt=\"{x:.1e}\",size=2)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"Covariance-MatrixV2.jpg\",dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization by Ridge regression\n",
    "\\begin{equation}\n",
    "\\bold{W} = (\\bold{X}^T\\bold{X}+\\lambda\\bold{I})^{-1}\\bold{X}^T\\bold{y},\\quad \\lambda\\geq0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of NaN features: 43\n"
     ]
    }
   ],
   "source": [
    "## Loading data\n",
    "TRAIN_FILEPATH = \"Data/train.csv\"\n",
    "TEST_FILEPATH  = \"Data/test.csv\"\n",
    "\n",
    "Training_data = pd.read_csv(TRAIN_FILEPATH)\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)\n",
    "\n",
    "## Extracting sales prices (labels) as numpy array\n",
    "Labels = Training_data[\"SalePrice\"].values\n",
    "\n",
    "## Extraxting feature names \n",
    "Feature_names = Training_data.columns[1:-1]\n",
    "\n",
    "## Getting features not represented by a number \n",
    "NaN_features = []\n",
    "for index, datatype in enumerate(Training_data.dtypes):\n",
    "    if datatype == \"O\" or datatype == object:\n",
    "        NaN_features.append(Training_data.columns[index])\n",
    "print(\"Nr. of NaN features:\",len(NaN_features))\n",
    "\n",
    "## Dictionary of dictionaries for integer embedding of NaN features\n",
    "\"\"\"A dictionary for each NaN feature, mapping k'th possible val for that feature to int(k)\"\"\"\n",
    "NaN_feature_dicts = {}\n",
    "for feature_idx,feature in enumerate(NaN_features):\n",
    "    ith_feature_dict = {}\n",
    "    for val_idx, possible_val in enumerate(np.unique(list(Training_data[NaN_features[feature_idx]]))):\n",
    "        ith_feature_dict[str(possible_val)] = val_idx\n",
    "    NaN_feature_dicts[feature] = ith_feature_dict   \n",
    "\n",
    "## Mapping all NaN features to numbers in compliance with dictionaries above (embedding)\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Training_data[feature]))):\n",
    "        value = current_dict[str(Training_data.at[index,feature])] ## Getting\n",
    "        Training_data.at[index,feature] = value                    ## Setting\n",
    "\n",
    "## Transforming from Pandas datafram to numpy array \n",
    "Training_data   = Training_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Feature_vectors = Training_data[:,[i+1 for i in range(Training_data.shape[1]-2)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Feature_vectors = Feature_vectors.astype(\"float64\")\n",
    "Feature_vectors = np.nan_to_num(Feature_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. deviation after normalization (ridge regression) = 0.1089 ( 10.89 %)\n",
      "Coefficient of determination is:  0.8546261977386495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######## Normalizing s.t. each feature (column) has mean = 0 and then variance = 1 ########\n",
    "# Labels\n",
    "Label_mean, Label_var = np.mean(Labels), np.std(Labels) \n",
    "Labels = Labels - Label_mean     ## mean\n",
    "Labels = Labels * 1./Label_var   ## variance\n",
    "# Feature vectors\n",
    "for col in range(Feature_vectors.shape[1]):\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] - np.mean(Feature_vectors[:,col])       ## mean\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] * 1./np.std(Feature_vectors[:,col])     ## variance\n",
    "\n",
    "\n",
    "X_init_norm_ridge = deepcopy(Feature_vectors)\n",
    "# Adding 1 as first coord to all feature vectors\n",
    "X_norm_ridge = np.ones((X_init_norm_ridge.shape[0],X_init_norm_ridge.shape[1]+1)) \n",
    "for col in range(1,X_norm_ridge.shape[1]):\n",
    "    X_norm_ridge[:,col] = X_init_norm_ridge[:,col-1]\n",
    "\n",
    "lmbda = 0.1\n",
    "I = np.identity(X_norm_ridge.shape[1])\n",
    "# Computing optimal weight vector\n",
    "Y_norm_ridge = Labels\n",
    "XT_norm_ridge = X_norm_ridge.T\n",
    "XTX_norm_ridge = XT_norm_ridge @ X_norm_ridge\n",
    "XTX_INVERSE_norm_ridge = np.linalg.inv(XTX_norm_ridge + lmbda * I)\n",
    "W_optimal_norm_ridge = ((XTX_INVERSE_norm_ridge @ XT_norm_ridge) @ Y_norm_ridge)\n",
    "\n",
    "deviation = 0\n",
    "for i in range(len(X_norm)):\n",
    "    deviation += np.abs(predict(X_norm_ridge[i],W_optimal_norm_ridge)*Label_var+Label_mean-(Y_norm_ridge[i]*Label_var+Label_mean))/np.abs(Y_norm_ridge[i]*Label_var+Label_mean)\n",
    "deviation *= 1./X.shape[0]\n",
    "print(\"Avg. deviation after normalization (ridge regression) =\",np.round(deviation,4),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "y_pred = np.array([predict(X_norm_ridge[i],W_optimal_norm_ridge)*Label_var+Label_mean for i in range(X_norm_ridge.shape[0])]) \n",
    "y_true = Y_norm_ridge*Label_var+Label_mean\n",
    "R2_coef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "#### Predicted price, actual price ####\n",
      "     124685.4       , 129500.0 \n",
      "----------------------------------------\n",
      "####           Deviation           ####\n",
      "                 3.7 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Single predictions (accounting for normalization)\n",
    "nr = 10\n",
    "print(\"-\"*40)\n",
    "print(\"#### Predicted price, actual price ####\")\n",
    "print(\"    \",np.round(predict(X_norm_ridge[nr],W_optimal_norm_ridge)*Label_var+Label_mean,1),\"      ,\",(Y_norm[nr]*Label_var)+Label_mean,\"\")\n",
    "print(\"-\"*40)\n",
    "print(\"####           Deviation           ####\")\n",
    "dev = np.round(100*np.abs(predict(X_norm_ridge[nr],W_optimal_norm_ridge)*Label_var+Label_mean-(Y_norm_ridge[nr]*Label_var+Label_mean))/np.abs(Y_norm_ridge[nr]*Label_var+Label_mean),1)\n",
    "print(f'                 {dev} %')\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization by Lasso regression (no closed form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. deviation after normalization (lasso regression) = 0.1066 ( 10.66 %)\n",
      "Coefficient of determination is:  0.8505634691722745\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "## Loading data\n",
    "TRAIN_FILEPATH = \"Data/train.csv\"\n",
    "TEST_FILEPATH  = \"Data/test.csv\"\n",
    "\n",
    "Training_data = pd.read_csv(TRAIN_FILEPATH)\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)\n",
    "\n",
    "## Extracting sales prices (labels) as numpy array\n",
    "Labels = Training_data[\"SalePrice\"].values\n",
    " \n",
    "## Mapping all NaN features to numbers in compliance with dictionaries above (embedding)\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Training_data[feature]))):\n",
    "        value = current_dict[str(Training_data.at[index,feature])] ## Getting\n",
    "        Training_data.at[index,feature] = value                    ## Setting\n",
    "\n",
    "## Transforming from Pandas datafram to numpy array \n",
    "Training_data   = Training_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Feature_vectors = Training_data[:,[i+1 for i in range(Training_data.shape[1]-2)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Feature_vectors = Feature_vectors.astype(\"float64\")\n",
    "Feature_vectors = np.nan_to_num(Feature_vectors)\n",
    "\n",
    "######## Normalizing s.t. each feature (column) has mean = 0 and then variance = 1 ########\n",
    "# Labels\n",
    "Label_mean, Label_var = np.mean(Labels), np.std(Labels) \n",
    "Labels = Labels - Label_mean     ## mean\n",
    "Labels = Labels * 1./Label_var   ## variance\n",
    "# Feature vectors\n",
    "for col in range(Feature_vectors.shape[1]):\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] - np.mean(Feature_vectors[:,col])       ## mean\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] * 1./np.std(Feature_vectors[:,col])     ## variance\n",
    "\n",
    "# Adding 1 as first coord to all feature vectors\n",
    "X_norm_lasso = np.ones((Feature_vectors.shape[0],Feature_vectors.shape[1]+1)) \n",
    "for col in range(1,X_norm_lasso.shape[1]):\n",
    "    X_norm_lasso[:,col] = Feature_vectors[:,col-1]\n",
    "\n",
    "## Performing lasso regression\n",
    "clf = linear_model.Lasso(alpha=0.007)\n",
    "clf.fit(X=X_norm_lasso,y=Labels)\n",
    "W_optimal_norm_lasso = np.concatenate([[clf.intercept_],clf.coef_[1:]])\n",
    "\n",
    "deviation = 0\n",
    "for i in range(len(X_norm)):\n",
    "    deviation += np.abs(predict(X_norm_lasso[i],W_optimal_norm_lasso)*Label_var+Label_mean-(Y_norm_ridge[i]*Label_var+Label_mean))/np.abs(Labels[i]*Label_var+Label_mean)\n",
    "deviation *= 1./X.shape[0]\n",
    "print(\"Avg. deviation after normalization (lasso regression) =\",np.round(deviation,4),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "y_pred = np.array([predict(X_norm_lasso[i],W_optimal_norm_lasso)*Label_var+Label_mean for i in range(X_norm_lasso.shape[0])]) \n",
    "y_true = Y_norm_ridge*Label_var+Label_mean\n",
    "R2_coef(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "#### Predicted price, actual price ####\n",
      "     124204.2       , 129500.0 \n",
      "----------------------------------------\n",
      "####           Deviation           ####\n",
      "                 4.1 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Single predictions (accounting for normalization)\n",
    "nr = 10\n",
    "print(\"-\"*40)\n",
    "print(\"#### Predicted price, actual price ####\")\n",
    "print(\"    \",np.round(predict(X_norm_lasso[nr],W_optimal_norm_lasso)*Label_var+Label_mean,1),\"      ,\",(Y_norm[nr]*Label_var)+Label_mean,\"\")\n",
    "print(\"-\"*40)\n",
    "print(\"####           Deviation           ####\")\n",
    "dev = np.round(100*np.abs(predict(X_norm_lasso[nr],W_optimal_norm_lasso)*Label_var+Label_mean-(Y_norm_ridge[nr]*Label_var+Label_mean))/np.abs(Y_norm_ridge[nr]*Label_var+Label_mean),1)\n",
    "print(f'                 {dev} %')\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regression Tree with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. deviation after normalization (Reg. tree w. AdaBoost) = 0.0124 ( 1.24 %)\n",
      "Coefficient of determination is:  0.9977179786400762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "## Loading data\n",
    "TRAIN_FILEPATH = \"Data/train.csv\"\n",
    "TEST_FILEPATH  = \"Data/test.csv\"\n",
    "\n",
    "Training_data = pd.read_csv(TRAIN_FILEPATH)\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)\n",
    "\n",
    "## Extracting sales prices (labels) as numpy array\n",
    "Labels = Training_data[\"SalePrice\"].values\n",
    " \n",
    "## Mapping all NaN features to numbers in compliance with dictionaries above (embedding)\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Training_data[feature]))):\n",
    "        value = current_dict[str(Training_data.at[index,feature])] ## Getting\n",
    "        Training_data.at[index,feature] = value                    ## Setting\n",
    "\n",
    "## Transforming from Pandas datafram to numpy array \n",
    "Training_data   = Training_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Feature_vectors = Training_data[:,[i+1 for i in range(Training_data.shape[1]-2)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Feature_vectors = Feature_vectors.astype(\"float64\")\n",
    "Feature_vectors = np.nan_to_num(Feature_vectors)\n",
    "\n",
    "######## Normalizing s.t. each feature (column) has mean = 0 and then variance = 1 ########\n",
    "# Labels\n",
    "Label_mean, Label_var = np.mean(Labels), np.std(Labels) \n",
    "Labels = Labels - Label_mean     ## mean\n",
    "Labels = Labels * 1./Label_var   ## variance\n",
    "\n",
    "# Feature vectors\n",
    "for col in range(Feature_vectors.shape[1]):\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] - np.mean(Feature_vectors[:,col])       ## mean\n",
    "    Feature_vectors[:,col] = Feature_vectors[:,col] * 1./np.std(Feature_vectors[:,col])     ## variance\n",
    "\n",
    "# Adding 1 as first coord to all feature vectors\n",
    "X_norm_Ada = np.ones((Feature_vectors.shape[0],Feature_vectors.shape[1]+1)) \n",
    "for col in range(1,X_norm_Ada.shape[1]):\n",
    "    X_norm_Ada[:,col] = Feature_vectors[:,col-1]\n",
    "\n",
    "# Fit regression model\n",
    "regression_loss_funcs = ['linear','square','exponential']\n",
    "base_reg = DecisionTreeRegressor(max_depth=15)\n",
    "regr_2 = AdaBoostRegressor(base_estimator=base_reg, n_estimators=68, \n",
    "                           learning_rate = 0.775, loss=regression_loss_funcs[1], random_state=0)\n",
    "\n",
    "regr_2.fit(X_norm_Ada, Labels.flatten())\n",
    "\n",
    "# Predict\n",
    "y_pred = regr_2.predict(X_norm_Ada)*Label_var+Label_mean\n",
    "y_true = Labels*Label_var+Label_mean\n",
    "\n",
    "# Score\n",
    "deviation = 0\n",
    "for i in range(len(X_norm)):\n",
    "    deviation += np.abs(y_pred[i]-y_true[i])/np.abs(y_true[i])\n",
    "deviation *= 1./X_norm_Ada.shape[0]\n",
    "print(\"Avg. deviation after normalization (Reg. tree w. AdaBoost) =\",np.round(deviation,4),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "R2_coef(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Adaboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. deviation after normalization (Reg. tree w. AdaBoost) = 0.0118 ( 1.18 %)\n",
      "Coefficient of determination is:  0.9977963065695571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "########## TRAINING DATA ##########\n",
    "## Loading data\n",
    "TRAIN_FILEPATH = \"Data/train.csv\"\n",
    "Training_data = pd.read_csv(TRAIN_FILEPATH)\n",
    "\n",
    "## Getting features not represented by a number \n",
    "NaN_features = []\n",
    "for index, datatype in enumerate(Training_data.dtypes):\n",
    "    if datatype == \"O\" or datatype == object:\n",
    "        NaN_features.append(Training_data.columns[index])\n",
    "\n",
    "## Dictionary of dictionaries\n",
    "\"\"\"A dictionary for each NaN feature, mapping k'th possible val for that feature to int(k)\"\"\"\n",
    "NaN_feature_dicts = {}\n",
    "for feature_idx,feature in enumerate(NaN_features):\n",
    "    ith_feature_dict = {}\n",
    "    for val_idx, possible_val in enumerate(np.unique(list(Training_data[NaN_features[feature_idx]]))):\n",
    "        ith_feature_dict[str(possible_val)] = val_idx\n",
    "    NaN_feature_dicts[feature] = ith_feature_dict   \n",
    "\n",
    "## Mapping all NaN features to numbers in compliance with dictionaries above (embedding)\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Training_data[feature]))):\n",
    "        if str(Training_data.at[index,feature]) not in list(current_dict.keys()):\n",
    "            print(str(Training_data.at[index,feature]),'Not in dictionary')\n",
    "        value = current_dict[str(Training_data.at[index,feature])] ## Getting\n",
    "        Training_data.at[index,feature] = value                    ## Setting\n",
    "\n",
    "## Extracting sales prices (labels) as numpy array\n",
    "Training_Labels = Training_data[\"SalePrice\"].values\n",
    "\n",
    "## Transforming from Pandas datafram to numpy array \n",
    "Training_data = Training_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Training_Feature_vectors = Training_data[:,[i+1 for i in range(Training_data.shape[1]-2)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Training_Feature_vectors = Training_Feature_vectors.astype(\"float64\")\n",
    "Training_Feature_vectors = np.nan_to_num(Training_Feature_vectors)\n",
    "\n",
    "## Normalizing s.t. each feature (column) has mean = 0 and then variance = 1 \n",
    "# Labels\n",
    "Training_Label_mean, Training_Label_var = np.mean(Training_Labels), np.std(Training_Labels) \n",
    "Training_Labels = Training_Labels - Training_Label_mean     ## mean\n",
    "Training_Labels = Training_Labels * 1./Training_Label_var   ## variance\n",
    "\n",
    "# Feature vectors\n",
    "for col in range(Training_Feature_vectors.shape[1]):\n",
    "    Training_Feature_vectors[:,col] = Training_Feature_vectors[:,col] - np.mean(Training_Feature_vectors[:,col])       ## mean\n",
    "    Training_Feature_vectors[:,col] = Training_Feature_vectors[:,col] * 1./np.std(Training_Feature_vectors[:,col])     ## variance\n",
    "\n",
    "Training_X_norm_Ada = Training_Feature_vectors\n",
    "\n",
    "\n",
    "########## TEST DATA ##########\n",
    "## Loading data\n",
    "TEST_FILEPATH = \"Data/test.csv\"\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)\n",
    "## Getting features not represented by a number \n",
    "NaN_features = []\n",
    "for index, datatype in enumerate(Test_data.dtypes):\n",
    "    if datatype == \"O\" or datatype == object:\n",
    "        NaN_features.append(Test_data.columns[index])\n",
    "\n",
    "## Dictionary of dictionaries\n",
    "\"\"\"A dictionary for each NaN feature, mapping k'th possible val for that feature to int(k)\"\"\"\n",
    "NaN_feature_dicts = {}\n",
    "for feature_idx,feature in enumerate(NaN_features):\n",
    "    ith_feature_dict = {}\n",
    "    for val_idx, possible_val in enumerate(np.unique(list(Test_data[NaN_features[feature_idx]]))):\n",
    "        ith_feature_dict[str(possible_val)] = val_idx\n",
    "    NaN_feature_dicts[feature] = ith_feature_dict   \n",
    "\n",
    "## Mapping all NaN features to numbers in compliance with dictionaries above (embedding)\n",
    "for feature in NaN_features:\n",
    "    current_dict = NaN_feature_dicts[feature] \n",
    "    for index in range(len(list(Test_data[feature]))):\n",
    "        if str(Test_data.at[index,feature]) not in list(current_dict.keys()):\n",
    "            print(str(Test_data.at[index,feature]),'Not in dictionary')\n",
    "        value = current_dict[str(Test_data.at[index,feature])] ## Getting\n",
    "        Test_data.at[index,feature] = value                    ## Setting\n",
    "\n",
    "## Transforming from Pandas datafram to numpy array \n",
    "Test_data = Test_data.values\n",
    "## Removing first column of data (only a numbering), and last column (labels)\n",
    "Test_Feature_vectors = Test_data[:,[i+1 for i in range(Test_data.shape[1]-1)]] \n",
    "## Assuring appropriate dtype of all entries in array (also setting any Nan = 0)\n",
    "Test_Feature_vectors = Test_Feature_vectors.astype(\"float64\")\n",
    "Test_Feature_vectors = np.nan_to_num(Test_Feature_vectors)\n",
    "\n",
    "# Feature vectors\n",
    "for col in range(Test_Feature_vectors.shape[1]):\n",
    "    Test_Feature_vectors[:,col] = Test_Feature_vectors[:,col] - np.mean(Test_Feature_vectors[:,col])       ## mean\n",
    "    Test_Feature_vectors[:,col] = Test_Feature_vectors[:,col] * 1./np.std(Test_Feature_vectors[:,col])     ## variance\n",
    "\n",
    "Test_X_norm_Ada = Test_Feature_vectors\n",
    "\n",
    "######### Fit regression model #########\n",
    "regression_loss_funcs = ['linear','square','exponential']\n",
    "base_reg = DecisionTreeRegressor(max_depth=15)\n",
    "reg = AdaBoostRegressor(base_estimator=base_reg, n_estimators=65, \n",
    "                        learning_rate = 0.775, loss=regression_loss_funcs[1], random_state=0)\n",
    "\n",
    "## Training model on training data\n",
    "reg.fit(Training_X_norm_Ada, Training_Labels.flatten())\n",
    "\n",
    "## Predict\n",
    "y_pred_test = reg.predict(Test_X_norm_Ada)*Training_Label_var+Training_Label_mean\n",
    "y_pred_training = reg.predict(Training_X_norm_Ada)*Training_Label_var+Training_Label_mean\n",
    "y_true_training = Training_Labels*Training_Label_var+Training_Label_mean\n",
    "\n",
    "# Score\n",
    "deviation = 0\n",
    "for i in range(len(X_norm)):\n",
    "    deviation += np.abs(y_pred_training[i]-y_true_training[i])/np.abs(y_true_training[i])\n",
    "deviation *= 1./Training_X_norm_Ada.shape[0]\n",
    "print(\"Avg. deviation after normalization (Reg. tree w. AdaBoost) =\",np.round(deviation,4),\"(\",np.round(deviation*100,2),\"%)\")\n",
    "R2_coef(y_true_training,y_pred_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "\n",
    "TEST_FILEPATH = \"Data/test.csv\"\n",
    "Test_data = pd.read_csv(TEST_FILEPATH)\n",
    "Test_data_Id = Test_data.values[:,0]\n",
    "id_n_prediction = []\n",
    "for i in range(len(Test_data_Id)):\n",
    "    id_n_prediction.append([int(Test_data_Id[i]),y_pred_test[i]])\n",
    "id_n_prediction = np.array(id_n_prediction)\n",
    "\n",
    "header = ['Id', 'SalePrice']\n",
    "with open('Submissions/predictions4.csv', 'w', ) as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write the data\n",
    "    for i in range(len(Test_data_Id)):\n",
    "        writer.writerow([int(id_n_prediction[i][0]),id_n_prediction[i][1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 2)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_n_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de9184fb1100b1b99a61021f59422ac28d78a243336732ae833608768c206ac0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
